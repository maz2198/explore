{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics: GINI & KS \n",
    "\n",
    "<img src=\"img/bannerlogo.jpg\" width=400 height=400 align=\"center\">\n",
    "\n",
    "**Explore Data Science Academy**\n",
    "\n",
    "**Author:** [Marang Mutloatse](https://www.linkedin.com/in/marangmutloatse/)\n",
    "\n",
    "**Email:** <marangmutloatse@gmail.com> \n",
    "\n",
    "**Last Revision**: 23 August 2020\n",
    "\n",
    "**version**: 1.2\n",
    "\n",
    "- **For the best viewing experience, one should [view this notebook in nbviewer].**\n",
    "- **With no local installation required, you can also [execute the code in this notebook on Binder]**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "- buwbb\n",
    "- kbfwi\n",
    " - iwbqfib\n",
    " - oqwifb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "- fallen heros\n",
    "- waving not "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Where:\n",
    "- **TP** = True Positive - True Positive - It is 1 and I rate it as 1.\n",
    "- **TN** = True Negative - True Negative - It is 0 and I rate it as 0.\n",
    "- **FN** = False Negative - False Negative.\n",
    "- **FP** = False Positive - Positive False.\n",
    "\n",
    "\n",
    "* Accuracy (accuracy) answers the question, *What is the proportion of correct predictions?*\n",
    "\n",
    "\\begin{equation*}\n",
    "accuracy =\n",
    "\\frac{( TP + TN )} {Total ( TP + TN + FP + FN)}\n",
    "\\end{equation*}\n",
    "\n",
    "* Sensitivity (recall) or Percent Support (support) answers the question, *What proportion of real positives have been correctly predicted?*\n",
    "\\begin{equation*}\n",
    "recall =\n",
    "\\frac{( TP )} {( TP + FN)}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "* Precision (Confidence) responds to the question *What proportion of my positive predictions is correct?*\n",
    "\\begin{equation*}\n",
    "precision =\n",
    "\\frac{( TP )} {( TP + FP)}\n",
    "\\end{equation*}\n",
    "\n",
    "Note that sensitivity and accuracy are defined here as proportion of real positives and proportion of positive predictions.\n",
    "\n",
    "### F1-score\n",
    "\n",
    "The F1-score is a classifying metric that calculates a mean of accuracy and recall in a way that emphasizes the lowest value.\n",
    "\n",
    "It is calculated as the harmonic average of precision and recall, where an F1-score reaches its best value at 1 (perfect accuracy and reminder) and the worst at 0.\n",
    "\n",
    "\n",
    "### Harmonic Average\n",
    "\n",
    "The harmonic mean is defined as the inverse of the arithmetic mean of the inverses. Because of that, the result is not sensitive to extremely large values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation and Required Libraries\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on *python 3x* and uses several Python packages that come standard with the Anaconda Python distribution. The primary libraries that we'll be using are:\n",
    "\n",
    "- [NumPy](https://numpy.org/install/)\n",
    "- [pandas](https://pandas.pydata.org/pandas-docs/version/0.17.0/install.html)\n",
    "- [scikit-learn](https://scikit-learn.org/stable/install.html)\n",
    "- [matplotlib](https://matplotlib.org/3.3.1/users/installing.html)\n",
    "- [warnings](https://docs.python.org/3/library/warnings.html)\n",
    "\n",
    "To ensure you have all of the packages to run the notebook, install them with `conda`:\n",
    "\n",
    "    conda install numpy pandas scikit-learn matplotlib warnings\n",
    "\n",
    "`Conda` may prompt an update if the most recent version is not installed. Allow it to do so.\n",
    "\n",
    "**Note:** Ideally in an end-to-end Machine learning project, one would create an [environment](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html) with the packages and the correct versions for the specific model. To see more about MLOps and the machine learning pipeline, read [here](https://christophergs.com/machine%20learning/2019/03/17/how-to-deploy-machine-learning-models/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Suppressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Check\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/maz2198/explore/master/data/creditcard_transaction_fraud_full.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.index = df.iloc[:,0]\n",
    "df = df.drop(df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41647, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>merchant_category_code_cat</th>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>merchant_category_code_previoustransaction_cat</th>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_cat</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_previoustransaction_cat</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_value_cat</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_value_previoustransaction_cat</th>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_entry</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creditcard_limit_cat</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_visa_mastercard_cat</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_of_creditcard_cat</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraudscore_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_person_cat</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trans_nacional_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numb_of_installments_cat</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transactionspeed_cat</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dif_fraudscore_cat</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_limit_cat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TARGET</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0                                         0     1     2    3     4\n",
       "merchant_category_code_cat                       9.0  22.0  22.0  9.0  15.0\n",
       "merchant_category_code_previoustransaction_cat  22.0  22.0  22.0  0.0   9.0\n",
       "zipcode_cat                                      3.0   3.0   3.0  2.0   2.0\n",
       "zipcode_previoustransaction_cat                  3.0   3.0   3.0  0.0   2.0\n",
       "transaction_value_cat                            6.0   7.0   7.0  4.0   4.0\n",
       "transaction_value_previoustransaction_cat        6.0   7.0   7.0  1.0   4.0\n",
       "pos_entry                                        2.0   2.0   2.0  2.0   2.0\n",
       "creditcard_limit_cat                             6.0   6.0   6.0  4.0   4.0\n",
       "brand_visa_mastercard_cat                        2.0   2.0   2.0  2.0   2.0\n",
       "type_of_creditcard_cat                           3.0   3.0   3.0  3.0   3.0\n",
       "fraudscore_cat                                   0.0   0.0   3.0  0.0   0.0\n",
       "type_person_cat                                  1.0   1.0   1.0  1.0   1.0\n",
       "trans_nacional_cat                               0.0   0.0   0.0  0.0   0.0\n",
       "numb_of_installments_cat                         1.0   1.0   1.0  1.0   1.0\n",
       "transactionspeed_cat                             7.0   4.0   6.0  2.0   3.0\n",
       "dif_fraudscore_cat                               1.0   4.0   5.0  3.0   3.0\n",
       "transaction_limit_cat                            0.0   0.0   0.0  0.0   0.0\n",
       "TARGET                                           0.0   0.0   1.0  0.0   0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraud Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03743366869162244\n"
     ]
    }
   ],
   "source": [
    "print(df['TARGET'].sum() / df['TARGET'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "The dataset has been downsampled 100x (reducing non-fraud cases randomly)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Oversampling__ is a technique where one replicates (oversample) the minority class (fraud) in order to balance different costs for false positives and false negatives. Oversampling of minority class is recomended for small/medium dataset sizes.\n",
    "\n",
    "__Undersampling__ is a technique where one samples the majority class (non-fraud) down rate in order to balance different costs for false positives and false negatives. Undersampling the majority class is recomended for big/huge dataset sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Fraud Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003887432521627116\n"
     ]
    }
   ],
   "source": [
    "print(df['TARGET'].sum() / ((df['TARGET'].count()-df['TARGET'].sum())*100+df['TARGET'].sum()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.887432521627116 basis points\n"
     ]
    }
   ],
   "source": [
    "print(10000*df['TARGET'].sum() / ((df['TARGET'].count()-df['TARGET'].sum())*100+df['TARGET'].sum()),\"basis points\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test-split\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (33317, 18)\n",
      "Dataset shape: (8330, 18)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "splitter = train_test_split\n",
    "\"-----------------------\"\n",
    "\n",
    "df_train, df_test = splitter(df, test_size = 0.2, random_state = 42)\n",
    "print(\"Dataset shape: {shape}\".format(shape = df_train.shape))\n",
    "print(\"Dataset shape: {shape}\".format(shape = df_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the final variables and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_columns(df, data_types, to_ignore = list(), ignore_target = False):\n",
    "    columns = df.select_dtypes(include=data_types).columns\n",
    "    if ignore_target:\n",
    "        columns = filter(lambda x: x not in to_ignore, list(columns))\n",
    "    return list(columns)\n",
    "\n",
    "target = \"TARGET\"\n",
    "variables = list(get_specific_columns(df, [\"float64\", \"int64\"], [target], ignore_target = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= df_train[variables]\n",
    "y_train = df_train[target]\n",
    "\n",
    "X_test= df_test[variables]\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0)\n",
    "fitted_model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the Predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = fitted_model.predict(X_train)\n",
    "pred_test  = fitted_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOW CALCULATE ACCURACY SEPARATING train AND test SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy* Train: 0.9617312483116727\n",
      "Accuracy* Test: 0.9623049219687875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy* Train: {0}\".format(accuracy_score(y_train,pred_train)))\n",
    "print(\"Accuracy* Test: {0}\".format(accuracy_score(y_test,pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as Fraud Rate is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003887432521627116\n"
     ]
    }
   ],
   "source": [
    "print(df['TARGET'].sum() / ((df['TARGET'].count()-df['TARGET'].sum())*100+df['TARGET'].sum()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model that predicts all cases to be non-fraud has an accuracy of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996112567478372"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-df['TARGET'].sum() / ((df['TARGET'].count()-df['TARGET'].sum())*100+df['TARGET'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use GINI and KS to see if there is any thing good about our model. For further explanation on `GINI` & `KS`, watch this short video on [Gini & KS Statistics in Credit Scoring](https://youtu.be/MiBUBVUC8kE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the probability of being fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_proba = fitted_model.predict_proba(X_train)[:,1]\n",
    "pred_test_proba  = fitted_model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Scikit-learn`, `pandas` or `statsmodels` do not have a specific function to calculate GINI and KS, so below is a function developed by [Manoel Gadi Fernando Alonso](https://www.linkedin.com/in/manoel-gadi-97821213/) and [Marang Mutloatse](https://github.com/maz2198)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calculate_gini_score(a,b):\n",
    "    \"\"\"Function that receives two parameters; first: \n",
    "    a binary variable representing 0=good and 1=bad, and then a second variable with the prediction of the first variable, \n",
    "    the second variable can be continuous, integer or binary - continuous is better. Finally, the function returns the \n",
    "    GINI Coefficient of the two lists.\"\"\"    \n",
    "    gini = 2*roc_auc_score(a,b)-1\n",
    "    return gini\n",
    "\n",
    "def calculate_KS(b,a):  \n",
    "    \"\"\"Function that received two parameters; first: a binary variable representing 0=good and 1=bad, and then a second \n",
    "    variable with the prediction of the first variable, the second variable can be continuous, integer or binary - \n",
    "    continuous is better. Finally, the function returns the KS Statistics of the two lists.\"\"\"\n",
    "    try:\n",
    "        tot_bads=1.0*sum(b)\n",
    "        tot_goods=1.0*(len(b)-tot_bads)\n",
    "        elements = zip(*[a,b])\n",
    "        elements = sorted(elements,key= lambda x: x[0])\n",
    "        elements_df = pd.DataFrame({'probability': b,'gbi': a})\n",
    "        pivot_elements_df = pd.pivot_table(elements_df, values='probability', index=['gbi'], aggfunc=[sum,len]).fillna(0)\n",
    "        max_ks = perc_goods = perc_bads = cum_perc_bads = cum_perc_goods = 0\n",
    "        for i in range(len(pivot_elements_df)):\n",
    "            perc_goods =  (pivot_elements_df.iloc[i]['len'] - pivot_elements_df.iloc[i]['sum']) / tot_goods\n",
    "            perc_bads = pivot_elements_df.iloc[i]['sum']/ tot_bads\n",
    "            cum_perc_goods += perc_goods\n",
    "            cum_perc_bads += perc_bads\n",
    "            A = cum_perc_bads-cum_perc_goods\n",
    "            if abs(A['probability']) > max_ks:\n",
    "                max_ks = abs(A['probability'])\n",
    "    except:\n",
    "        max_ks = 0\n",
    "    return max_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINI Score TRAIN: 0.7339339044545414\n",
      "GINI Score TEST: 0.7257933099007177\n"
     ]
    }
   ],
   "source": [
    "print(\"GINI Score TRAIN: {0}\".format(calculate_gini_score(y_train, pred_train_proba)))\n",
    "print(\"GINI Score TEST: {0}\".format(calculate_gini_score(y_test, pred_test_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31246,   816],\n",
       "       [  772,   483]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train, pred_train_proba>0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating KS for train and test samples\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Score TRAIN: 0.585001967055448\n",
      "KS Score TEST: 0.597569412566989\n"
     ]
    }
   ],
   "source": [
    "print(\"KS Score TRAIN: {0}\".format(calculate_KS(y_train, pred_train_proba)))\n",
    "print(\"KS Score TEST: {0}\".format(calculate_KS(y_test, pred_test_proba)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Reading\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Exercises\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Knowing what we know about `GINI` and `KS`, what would be the appropriate metric (**f1**, **accuracy**, **mcc** etc.) to use when performing cross validation? If possible, use several different classification models (Random Forest, Logit and Decision Tree) and [plot_comparisons](https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html). **Here is some code and few examples on plotting the [roc-auc curve](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html).**\n",
    "\n",
    "2. How/Is, the use of `GINI` and `KS` effective in multiclass classification problems? **Note: Focus on a specific industry and use case, this will ease answering this question**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
